{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tacotron-2 training\n",
    "\n",
    "This notebook provides examples to \n",
    "1. Create a new Tacotron2 model (pretrained or new one with transfer-learning) \\*\n",
    "2. Load dataset, test and analyze it\n",
    "3. Train the model on this dataset\n",
    "4. Complete inference with the `Waveglow` NVIDIA's pretrained vocoder\n",
    "\n",
    "\\* **Important** : when creating a new model with transfer learning (or from pretrained pytorch model), both models (pretrained and new one) are loaded in memory. It is necessary to restart the kernel before training to avoid `Out Of Memory (OOM)` errors !\n",
    "\n",
    "Note : this notebook does **not** retrain a model till convergence because some powerful French models are already shared. The execution is simply to assess that the code is working, and to give an example of outputs.\n",
    "\n",
    "The complete training procedure to have good performance model takes around 15 epochs (at least on SIWIS) with the `NVIDIA's pretrained` model (for `transfer-learning`), which takes (on my GeForce GTX1070) around 15h. \n",
    "It means that, in approximately 1 night of training, you can have a really good `Text-To-Speech synthesis` : quite impressive and funny !\n",
    "\n",
    "**Important Note** : if you do not have a working `pytorch GPU` installation, you have to download the `WaveGlow` weights for tensorflow, as well as the `pretrained_tacotron2` model (cf `README` file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports + model creation\n",
    "\n",
    "The 1st cell imports all necessary functions and define the global variable `model_name` which is the name of the model used in the whole notebook. \n",
    "\n",
    "The 4 next cells create new `Tacotron2` in different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.10.0\n",
      "Available GPU's (1) : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from models import get_pretrained\n",
    "from models.tts import Tacotron2, WaveGlow\n",
    "from custom_architectures import get_architecture\n",
    "from datasets import get_dataset, train_test_split, prepare_dataset, test_dataset_time\n",
    "from utils import plot_spectrogram, limit_gpu_memory\n",
    "from utils.text import default_french_encoder\n",
    "from utils.audio import display_audio, load_audio, load_mel\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "rate = 22050\n",
    "model_name = \"tacotron2_siwis\"\n",
    "\n",
    "print(\"Tensorflow version : {}\".format(tf.__version__))\n",
    "print(\"Available GPU's ({}) : {}\".format(len(gpus), gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell creates a perfect copy of the NVIDIA's pretrained model (and name it \"nvidia_pretrained\")\n",
    "model = Tacotron2.from_nvidia_pretrained()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Text encoder ==========\n",
      "Vocab (size = 148) : ['_', '-', '!', \"'\", '(', ')', ',', '.', ':', ';', '?', ' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l']\n",
      "Config : {\n",
      "  \"level\": 0,\n",
      "  \"lstrip\": false,\n",
      "  \"rstrip\": false,\n",
      "  \"cleaners\": [\n",
      "    {\n",
      "      \"name\": \"french_cleaners\",\n",
      "      \"to_lowercase\": false\n",
      "    }\n",
      "  ],\n",
      "  \"split_pattern\": null,\n",
      "  \"bpe_end_of_word\": null,\n",
      "  \"pad_token\": \"\",\n",
      "  \"sep_token\": null,\n",
      "  \"ukn_token\": null,\n",
      "  \"sos_token\": \"[SOS]\",\n",
      "  \"eos_token\": \"[EOS]\",\n",
      "  \"mask_token\": null,\n",
      "  \"sub_word_prefix\": \"\",\n",
      "  \"use_sos_and_eos\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# This special cleaner allow to not lowercase the text \n",
    "# see my data_processing repository for more examples on text encoding / cleaners\n",
    "# If you want lowercase, you just have to remove the \"cleaners\" argument from default_french_encoder()\n",
    "cleaners = [\n",
    "    {'name' : 'french_cleaners', 'to_lowercase' : False}\n",
    "]\n",
    "encoder = default_french_encoder(vocab_size = 148, cleaners = cleaners)\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell creates a new model based on the NVIDIA's pretrained model\n",
    "model = Tacotron2.from_nvidia_pretrained(\n",
    "    nom = model_name, lang = \"fr\", text_encoder = encoder\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restoration...\n",
      "Initializing submodel : `tts_model` !\n",
      "Successfully restored tts_model from pretrained_models/pretrained_tacotron2/saving/tts_model.json !\n",
      "Model pretrained_tacotron2 initialized successfully !\n",
      "Initializing model with kwargs : {'tts_model': {'architecture_name': 'tacotron2', 'pad_token': 0, 'vocab_size': 148, 'n_mel_channels': 80, 'init_step': 0}}\n",
      "Initializing submodel : `tts_model` !\n",
      "Submodel tts_model saved in pretrained_models\\tacotron2_siwis\\saving\\tts_model.json !\n",
      "Model tacotron2_siwis initialized successfully !\n",
      "Weights transfered successfully !\n",
      "Submodel tts_model saved in pretrained_models\\tacotron2_siwis\\saving\\tts_model.json !\n",
      "\n",
      "========== tacotron2_siwis ==========\n",
      "Sub model tts_model\n",
      "- Inputs \t: unknown\n",
      "- Outputs \t: unknown\n",
      "- Number of layers \t: 3\n",
      "- Number of parameters \t: 28.190 Millions\n",
      "- Model not compiled\n",
      "\n",
      "Transfer-learning from : pretrained_tacotron2\n",
      "Already trained on 0 epochs (0 steps)\n",
      "\n",
      "- Language : fr\n",
      "- Vocabulary (size = 148) : ['_', '-', '!', \"'\", '(', ')', ',', '.', ':', ';', '?', ' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', ...]\n",
      "- Audio rate : 22050\n",
      "- # mel channels : 80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This cell creates a new model based on a pretrained Tacotron2 model\n",
    "model = Tacotron2.from_pretrained(\n",
    "    nom = model_name, pretrained_name = 'pretrained_tacotron2',\n",
    "    lang = \"fr\", text_encoder = encoder\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model instanciation\n",
    "\n",
    "This cell loads the model based on its name. Once created, you **do not have** to put all its configuration again : they will be loaded automatically ! Furthermore, models are `singleton` so you can execute these cell as many times as you want but the model will not be reloaded every times !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restoration...\n",
      "Initializing submodel : `tts_model` !\n",
      "Successfully restored tts_model from pretrained_models/tacotron2_siwis/saving/tts_model.json !\n",
      "Model tacotron2_siwis initialized successfully !\n",
      "Optimizer 'tts_model_optimizer' initilized successfully !\n",
      "Submodel tts_model compiled !\n",
      "  Loss : {'reduction': 'none', 'name': 'tacotron_loss', 'mel_loss': 'mse', 'mask_mel_padding': True, 'label_smoothing': 0, 'finish_weight': 1.0, 'not_finish_weight': 1.0, 'from_logits': False}\n",
      "  Optimizer : {'name': 'Adam', 'learning_rate': {'class_name': 'WarmupScheduler', 'config': {'factor': 128.0, 'warmup_steps': 512, 'minval': 0.0001, 'maxval': 0.001}}, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "  Metrics : []\n",
      "\n",
      "========== tacotron2_siwis ==========\n",
      "Sub model tts_model\n",
      "- Inputs \t: unknown\n",
      "- Outputs \t: unknown\n",
      "- Number of layers \t: 3\n",
      "- Number of parameters \t: 28.190 Millions\n",
      "- Optimizer \t: {'name': 'Adam', 'learning_rate': {'class_name': 'WarmupScheduler', 'config': {'factor': 128.0, 'warmup_steps': 512, 'minval': 0.0001, 'maxval': 0.001}}, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "- Loss \t : {'reduction': 'none', 'name': 'tacotron_loss', 'mel_loss': 'mse', 'mask_mel_padding': True, 'label_smoothing': 0, 'finish_weight': 1.0, 'not_finish_weight': 1.0, 'from_logits': False}\n",
      "- Metrics\t : []\n",
      "\n",
      "Transfer-learning from : pretrained_tacotron2\n",
      "Already trained on 0 epochs (0 steps)\n",
      "\n",
      "- Language : fr\n",
      "- Vocabulary (size = 148) : ['_', '-', '!', \"'\", '(', ')', ',', '.', ':', ';', '?', ' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', ...]\n",
      "- Audio rate : 22050\n",
      "- # mel channels : 80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = get_pretrained(model_name)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam', \n",
    "    optimizer_config = {\n",
    "        'lr' : {\n",
    "            'name' : 'WarmupScheduler',\n",
    "            'maxval' : 1e-3,\n",
    "            'minval' : 1e-4,\n",
    "            'factor' : 128,\n",
    "            'warmup_steps' : 512\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset siwis...\n",
      "Dataset length : 9763\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'siwis'\n",
    "dataset = get_dataset(dataset_name)\n",
    "\n",
    "train, valid = None, None\n",
    "\n",
    "print(\"Dataset length : {}\".format(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>filename</th>\n",
       "      <th>mels_22050_chann-80_filt-1024_hop-256_win-1024_norm-None</th>\n",
       "      <th>wavs_16000</th>\n",
       "      <th>wavs_22050</th>\n",
       "      <th>wavs_44100</th>\n",
       "      <th>time</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benoît Hamon, monsieur le ministre, ce texte, ...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\mels_22050_chann-80_filt-...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs_16000\\part1\\neut_par...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs_22050\\part1\\neut_par...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>siwis</td>\n",
       "      <td>siwis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cette lutte se situe à deux niveaux.</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\mels_22050_chann-80_filt-...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs_16000\\part1\\neut_par...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs_22050\\part1\\neut_par...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>siwis</td>\n",
       "      <td>siwis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Venons-en maintenant au fond.</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\mels_22050_chann-80_filt-...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs_16000\\part1\\neut_par...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs_22050\\part1\\neut_par...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>siwis</td>\n",
       "      <td>siwis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peu à peu, ils mobilisent des moyens.</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\mels_22050_chann-80_filt-...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs_16000\\part1\\neut_par...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs_22050\\part1\\neut_par...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>siwis</td>\n",
       "      <td>siwis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S’il y a unanimité pour augmenter le volume, n...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\mels_22050_chann-80_filt-...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs_16000\\part1\\neut_par...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs_22050\\part1\\neut_par...</td>\n",
       "      <td>D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>siwis</td>\n",
       "      <td>siwis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   \n",
       "0  Benoît Hamon, monsieur le ministre, ce texte, ...  \\\n",
       "1               Cette lutte se situe à deux niveaux.   \n",
       "2                      Venons-en maintenant au fond.   \n",
       "3              Peu à peu, ils mobilisent des moyens.   \n",
       "4  S’il y a unanimité pour augmenter le volume, n...   \n",
       "\n",
       "                                            filename   \n",
       "0  D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...  \\\n",
       "1  D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...   \n",
       "2  D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...   \n",
       "3  D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...   \n",
       "4  D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...   \n",
       "\n",
       "  mels_22050_chann-80_filt-1024_hop-256_win-1024_norm-None   \n",
       "0  D:/datasets/SIWIS\\fr\\mels_22050_chann-80_filt-...        \\\n",
       "1  D:/datasets/SIWIS\\fr\\mels_22050_chann-80_filt-...         \n",
       "2  D:/datasets/SIWIS\\fr\\mels_22050_chann-80_filt-...         \n",
       "3  D:/datasets/SIWIS\\fr\\mels_22050_chann-80_filt-...         \n",
       "4  D:/datasets/SIWIS\\fr\\mels_22050_chann-80_filt-...         \n",
       "\n",
       "                                          wavs_16000   \n",
       "0  D:/datasets/SIWIS\\fr\\wavs_16000\\part1\\neut_par...  \\\n",
       "1  D:/datasets/SIWIS\\fr\\wavs_16000\\part1\\neut_par...   \n",
       "2  D:/datasets/SIWIS\\fr\\wavs_16000\\part1\\neut_par...   \n",
       "3  D:/datasets/SIWIS\\fr\\wavs_16000\\part1\\neut_par...   \n",
       "4  D:/datasets/SIWIS\\fr\\wavs_16000\\part1\\neut_par...   \n",
       "\n",
       "                                          wavs_22050   \n",
       "0  D:/datasets/SIWIS\\fr\\wavs_22050\\part1\\neut_par...  \\\n",
       "1  D:/datasets/SIWIS\\fr\\wavs_22050\\part1\\neut_par...   \n",
       "2  D:/datasets/SIWIS\\fr\\wavs_22050\\part1\\neut_par...   \n",
       "3  D:/datasets/SIWIS\\fr\\wavs_22050\\part1\\neut_par...   \n",
       "4  D:/datasets/SIWIS\\fr\\wavs_22050\\part1\\neut_par...   \n",
       "\n",
       "                                          wavs_44100  time dataset_name     id  \n",
       "0  D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...  -1.0        siwis  siwis  \n",
       "1  D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...  -1.0        siwis  siwis  \n",
       "2  D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...  -1.0        siwis  siwis  \n",
       "3  D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...  -1.0        siwis  siwis  \n",
       "4  D:/datasets/SIWIS\\fr\\wavs\\part1\\neut_parl_s01_...  -1.0        siwis  siwis  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The model is quite easy to train and has many `training hyperparameters` for audio processing\n",
    "\n",
    "You can easily train your own model on your dataset : the only information required by the model is a `pd.DataFrame` with `filename` and `text` columns (other fields are optional : the `wavs_22050` is the resampled file to speed up audio loading).\n",
    "\n",
    "The `id` and `time` fields are optional (used for dataset analysis).\n",
    "\n",
    "You can see `max_train_frames` and `pad_to_multiple` configuration but they are currently **not** supported. These are for splitted training where we train on the complete mel but by splitting it in sub parts but this is not working yet\n",
    "\n",
    "The `SIWIS` dataset is a really good quality dataset so it does not need any trimming / processing. I left the parameters to facilitate their modification if necessary for other datasets\n",
    "\n",
    "As you can observe, multiple losses are displayed (the general `loss` + `mel_loss`, `gate_loss` and `mel_postnet_loss`) : the `TacotronLoss` computes them to give a more *in-depth* view of the model performances. For the `wiehgts update`, only `loss` is used (which is the sum of the 3 other losses).\n",
    "\n",
    "The `train_size` and `valid_size` parameters can be given to `model.train` and the split will be done internally. I have decided to make it before training to show the actual number of batches ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples   : 640 - 20 batches\n",
      "Validation samples : 640 - 10 batches\n",
      "Training config :\n",
      "HParams :\n",
      "- augment_prct\t: 0.25\n",
      "- trim_audio\t: False\n",
      "- reduce_noise\t: False\n",
      "- trim_threshold\t: 0.075\n",
      "- max_silence\t: 0.25\n",
      "- trim_method\t: window\n",
      "- trim_mode\t: start_end\n",
      "- trim_mel\t: False\n",
      "- trim_factor\t: 0.6\n",
      "- trim_mel_method\t: max_start_end\n",
      "- max_input_length\t: 75\n",
      "- max_output_length\t: 512\n",
      "- max_train_frames\t: -1\n",
      "- pad_to_multiple\t: False\n",
      "- batch_size\t: 32\n",
      "- train_batch_size\t: None\n",
      "- valid_batch_size\t: 64\n",
      "- test_batch_size\t: 1\n",
      "- shuffle_size\t: 512\n",
      "- epochs\t: 5\n",
      "- verbose\t: 1\n",
      "- train_times\t: 1\n",
      "- valid_times\t: 1\n",
      "- train_size\t: None\n",
      "- valid_size\t: None\n",
      "- test_size\t: 4\n",
      "- pred_step\t: -1\n",
      "\n",
      "Running on 1 GPU\n",
      "\n",
      "Epoch 1 / 5\n",
      "Epoch 1/5\n",
      "     10/Unknown - 89s 7s/step - loss: 3.9265 - mse_mel_loss: 2.0723 - mse_mel_postnet_loss: 1.8121 - gate_loss: 0.0421Training interrupted ! Saving model...\n",
      "Training interrupted at epoch 0 !\n",
      "Training finished after 1min 35sec !\n",
      "Submodel tts_model saved in pretrained_models\\tacotron2_siwis\\saving\\tts_model.json !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<custom_train_objects.history.History at 0x175fa5dd840>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Classic hyperparameters \"\"\"\n",
    "epochs     = 5\n",
    "batch_size = 32\n",
    "valid_batch_size = 2 * batch_size\n",
    "train_prop = 0.9\n",
    "train_size = 640 #int(len(dataset) * train_prop)\n",
    "valid_size = 640 #min(len(dataset) - train_size, 250 * valid_batch_size)\n",
    "\n",
    "shuffle_size    = 16 * batch_size\n",
    "pred_step       = -1 # make a prediction after every epoch\n",
    "augment_prct    = 0.25\n",
    "\n",
    "\"\"\" Custom training hparams \"\"\"\n",
    "trim_audio      = False\n",
    "reduce_noise    = False\n",
    "trim_threshold  = 0.075\n",
    "max_silence     = 0.25\n",
    "trim_method     = 'window'\n",
    "trim_mode       = 'start_end'\n",
    "\n",
    "trim_mel     = False\n",
    "trim_factor  = 0.6\n",
    "trim_mel_method  = 'max_start_end'\n",
    "\n",
    "# These lengths corresponds to approximately 5s audio\n",
    "# This is the max my GPU supports for an efficient training but is large enough for the SIWIS dataset\n",
    "max_output_length = 512\n",
    "max_input_length = 75\n",
    "\n",
    "\"\"\" Training \"\"\"\n",
    "\n",
    "# this is to normalize dataset usage so that you can use a pre-splitted dataset or not\n",
    "# without changing anything in the training configuration\n",
    "if train is None or valid is None:\n",
    "    train, valid = train_test_split(\n",
    "        dataset, train_size = train_size, valid_size = valid_size, shuffle = True\n",
    "    )\n",
    "\n",
    "print(\"Training samples   : {} - {} batches\".format(\n",
    "    len(train), len(train) // batch_size\n",
    "))\n",
    "print(\"Validation samples : {} - {} batches\".format(\n",
    "    len(valid), len(valid) // valid_batch_size\n",
    "))\n",
    "\n",
    "model.train(\n",
    "    train, validation_data = valid, \n",
    "\n",
    "    epochs = epochs, batch_size = batch_size, valid_batch_size = valid_batch_size,\n",
    "    \n",
    "    max_input_length = max_input_length, max_output_length = max_output_length,\n",
    "    pred_step = pred_step, shuffle_size = shuffle_size, augment_prct = augment_prct,\n",
    "    \n",
    "    trim_audio = trim_audio, reduce_noise = reduce_noise, trim_threshold = trim_threshold,\n",
    "    max_silence = max_silence, trim_method = trim_method, trim_mode = trim_mode,\n",
    "    \n",
    "    trim_mel = trim_mel, trim_factor = trim_factor, trim_mel_method = trim_mel_method,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to show the power of the `History` configuration tracking :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training informations :\n",
      "                       start                        end       time   \n",
      "0 2023-04-29 15:40:33.606389 2023-04-29 15:42:09.077067  95.470678  \\\n",
      "\n",
      "   interrupted  start_epoch  final_epoch  \n",
      "0        False           -1            0  \n",
      "Training configurations :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>losses</th>\n",
       "      <th>optimizers</th>\n",
       "      <th>augment_prct</th>\n",
       "      <th>trim_audio</th>\n",
       "      <th>reduce_noise</th>\n",
       "      <th>trim_threshold</th>\n",
       "      <th>max_silence</th>\n",
       "      <th>trim_method</th>\n",
       "      <th>trim_mode</th>\n",
       "      <th>...</th>\n",
       "      <th>shuffle_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>verbose</th>\n",
       "      <th>train_times</th>\n",
       "      <th>valid_times</th>\n",
       "      <th>train_size</th>\n",
       "      <th>valid_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>pred_step</th>\n",
       "      <th>dataset_infos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'name': 'metric_list', 'dtype': 'float32', 'm...</td>\n",
       "      <td>{'tts_model_loss': {'reduction': 'none', 'name...</td>\n",
       "      <td>{'tts_model_optimizer': {'name': 'Adam', 'lear...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.25</td>\n",
       "      <td>window</td>\n",
       "      <td>start_end</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'train': {'text': {'# uniques': 640}, 'filena...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             metrics   \n",
       "0  {'name': 'metric_list', 'dtype': 'float32', 'm...  \\\n",
       "\n",
       "                                              losses   \n",
       "0  {'tts_model_loss': {'reduction': 'none', 'name...  \\\n",
       "\n",
       "                                          optimizers  augment_prct   \n",
       "0  {'tts_model_optimizer': {'name': 'Adam', 'lear...          0.25  \\\n",
       "\n",
       "   trim_audio  reduce_noise  trim_threshold  max_silence trim_method   \n",
       "0       False         False           0.075         0.25      window  \\\n",
       "\n",
       "   trim_mode  ...  shuffle_size  epochs verbose  train_times  valid_times   \n",
       "0  start_end  ...           512       5       1            1            1  \\\n",
       "\n",
       "   train_size  valid_size  test_size pred_step   \n",
       "0        None        None          4        -1  \\\n",
       "\n",
       "                                       dataset_infos  \n",
       "0  {'train': {'text': {'# uniques': 640}, 'filena...  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training informations :\")\n",
    "print(pd.DataFrame(model.history.trainings_infos))\n",
    "print(\"Training configurations :\")\n",
    "pd.DataFrame(model.history.trainings_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset analysis\n",
    "\n",
    "Dataset generation is quite fast compared to the training time : approximately 15-20 batches / sec. It demonstrates that the data generation pipeline is clearly not the bottleneck of the training process. Nevertheless, you can speed up training by increasing the number of frames generated at each inference step (1 by default) (this feature has not been properly tested, some errors may occur). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [00:06, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 batchs in 6.795 sec sec (14.717 batch / sec)\n",
      "\n",
      "Batch infos : \n",
      "Item 0 : \n",
      " Item 0 : shape : (32, 82) - type : int32- min : 0.000 - max : 68.000\n",
      " Item 1 : shape : (32, 441, 80) - type : float32- min : -16.130 - max : 3.896\n",
      " Item 2 : shape : (32,) - type : int32- min : 153.000 - max : 441.000\n",
      "Item 1 : \n",
      " Item 0 : shape : (32, 441, 80) - type : float32- min : -11.513 - max : 1.925\n",
      " Item 1 : shape : (32, 441) - type : float32- min : 0.000 - max : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.794913053512573"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = model.get_dataset_config(batch_size = 32, is_validation = False, shuffle_size = 0)\n",
    "ds = prepare_dataset(dataset, ** config)\n",
    "\n",
    "test_dataset_time(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waveglow inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restoration...\n",
      "Initializing submodel : `vocoder` !\n",
      "Successfully restored vocoder from pretrained_models/WaveGlow/saving/vocoder.json !\n",
      "[WARNING] Some layers have not bene restored from the checkpoint ! Run `model.load_checkpoint().assert_consumed()` to check if it is a critical error or not\n",
      "Model WaveGlow initialized successfully !\n",
      "Model restoration...\n",
      "Initializing submodel : `tts_model` !\n",
      "Successfully restored tts_model from pretrained_models/tacotron2_siwis/saving/tts_model.json !\n",
      "Model tacotron2_siwis initialized successfully !\n",
      "Loading dataset siwis...\n"
     ]
    }
   ],
   "source": [
    "#waveglow = PtWaveGlow() # for pytorch-based inference\n",
    "waveglow = WaveGlow()\n",
    "model    = Tacotron2(nom = model_name)\n",
    "\n",
    "dataset  = get_dataset('siwis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference based on dataset\n",
    "\n",
    "This cell displays 3 different audios : \n",
    "- The original one (i.e. the human speaking)\n",
    "- An *inverted* version : the prediction of `WaveGlow` on the ground truth `mel-spectrogram`\n",
    "- The `Tacotron-2` generated audio\n",
    "\n",
    "It is important to note that the general audio quality of the generated audio will (in theory) not be better than the inverted version. It therefore means that, if the inverted version is of poor quality, you will require another vocoder model for this speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, row in dataset.sample(2, random_state = 0).iterrows():\n",
    "    text     = row['text']\n",
    "    filename = row['filename']\n",
    "    \n",
    "    encoded  = model.encode_text(text)\n",
    "    \n",
    "    # text analysis\n",
    "    print(\"Text :\\n  Original text : {}\\n  Encoded text : {}\\n  Decoded text : {}\".format(\n",
    "        text, encoded, model.decode_text(encoded)\n",
    "    ))\n",
    "    \n",
    "    # mel analysis\n",
    "    original_mel     = load_mel(filename, model.mel_fn)\n",
    "    processed_mel    = model.get_mel_input(filename)\n",
    "    \n",
    "    plot_spectrogram(original = original_mel, processed = processed_mel, ncols = 2)\n",
    "    \n",
    "    # audio analysis\n",
    "    original_audio  = load_audio(filename, rate = rate)\n",
    "    inverted_audio  = waveglow.infer(original_mel)\n",
    "    \n",
    "    print(\"Original audio :\")\n",
    "    display_audio(original_audio, rate = rate)\n",
    "    print(\"Waveglow inversion based on the original mel-spectrogram\")\n",
    "    display_audio(inverted_audio, rate = rate)\n",
    "    \n",
    "    # Uncomment these lines to perform Tacotron-2 inference\n",
    "    _, predicted_mel, _, _ = model.infer(encoded)\n",
    "    predicted_audio = waveglow.infer(predicted_mel)\n",
    "    print('Predicted audio :')\n",
    "    display_audio(predicted_audio, rate = rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference based on custom text\n",
    "\n",
    "The 1st cell uses the `tts API` while the 2nd shows the complete pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models.tts import tts\n",
    "\n",
    "text = \"Bonjour à tous ! Voici une démonstration du modèle en français.\"\n",
    "\n",
    "_ = tts(text, model = model, directory = None, save = False, display = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Bonjour à tous ! Voici une démonstration du modèle en français.\"\n",
    "# Encode text\n",
    "encoded = model.encode_text(text)\n",
    "# Generate mel and attention results\n",
    "# The 1st output is the mel, 2nd is mel_postnet (final postnet after final processing)\n",
    "# the 3rd are 'gates' (deciding when to stop generation) and 4th are attention weights\n",
    "_, mel, _, attn = model.infer(encoded)\n",
    "# Make inference mel --> audio\n",
    "audio = waveglow.infer(mel)\n",
    "# Plot spectrogram + attention\n",
    "plot_spectrogram(spectrogram = mel, attention_weights = attn)\n",
    "# Display audio\n",
    "_ = display_audio(audio, rate = rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
